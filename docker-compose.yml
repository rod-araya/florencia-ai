services:
  florencia-ai-ollama:
    image: ollama/ollama:latest
    container_name: florencia-ai-ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"        # cambia a 11435:11434 si el 11434 est√° ocupado
    restart: unless-stopped

  florencia-ai:
    build:
      context: .
    image: florencia-ai:latest
    container_name: florencia-ai
    env_file:
      - .env
    environment:
      - TZ=${TZ}
    volumes:
      - ./app:/app
      - ./logs:/logs
      - ./shared:/shared
      - ./models:/models
    depends_on:
      - florencia-ai-ollama
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

volumes:
  ollama:
